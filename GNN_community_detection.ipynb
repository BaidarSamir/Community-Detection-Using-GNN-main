{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('visuals', exist_ok=True)\n",
        "\n",
        "def save_fig(fname):\n",
        "    \"\"\"Save the current matplotlib figure into the visuals folder and close it.\"\"\"\n",
        "    os.makedirs('visuals', exist_ok=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join('visuals', fname))\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd4F2_qpaggX"
      },
      "source": [
        "## CSI 4900- Community detection using GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg4p-EM0Vb17"
      },
      "source": [
        "<h4>Importing Necessary Libraries</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.2.6)\n",
            "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (3.9.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (3.4.2)\n",
            "Requirement already satisfied: torch in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.9.0)\n",
            "Requirement already satisfied: torch_geometric in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# (Optional, for Colab â€“ run once)\n",
        "!pip install numpy pandas matplotlib networkx torch torch_geometric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgvRK3tpIDNi",
        "outputId": "51169a45-95e8-4a49-e0dd-f5ebf6474d5b"
      },
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import json\n",
        "import collections\n",
        "\n",
        "# Third-party\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "from torch_geometric.nn import GCNConv\n",
        "import networkx as nx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BIKz6Z5Ut54"
      },
      "source": [
        "### Pre-processing the dataset\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we load the raw feature, edge, and label files from GitHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "QsSOg60FIM6x"
      },
      "outputs": [],
      "source": [
        "json_url = \"https://raw.githubusercontent.com/mehtameet12/GNN_Dataset/main/musae_git_features.json\"\n",
        "edges_url = \"https://raw.githubusercontent.com/mehtameet12/GNN_Dataset/main/musae_git_edges.csv\"\n",
        "target_url = \"https://raw.githubusercontent.com/mehtameet12/GNN_Dataset/main/musae_git_target.csv\"\n",
        "\n",
        "# Fetch JSON features\n",
        "response = requests.get(json_url)\n",
        "response.raise_for_status()  # raises a clear HTTPError if it fails\n",
        "data_raw = json.loads(response.text)\n",
        "\n",
        "# Fetch edges and targets\n",
        "edges = pd.read_csv(edges_url)\n",
        "target_df = pd.read_csv(target_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "l1Yyvc4Q53iv",
        "outputId": "5626f9bd-fb5e-462b-e475-718ad603c3b9",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 rows of the target (labels) dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>ml_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Eiryyy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>shawflying</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>JpMCarrilho</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>SuhwanCha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sunilangadi2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id          name  ml_target\n",
              "0   0        Eiryyy          0\n",
              "1   1    shawflying          0\n",
              "2   2   JpMCarrilho          1\n",
              "3   3     SuhwanCha          0\n",
              "4   4  sunilangadi2          1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"First 5 rows of the target (labels) dataset:\")\n",
        "display(target_df.head())  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "5qCq-3gG53iv",
        "outputId": "4739a3ad-34c6-4e91-9ca9-24b4a25b67c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last 5 rows of the target (labels) dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>ml_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37695</th>\n",
              "      <td>37695</td>\n",
              "      <td>shawnwanderson</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37696</th>\n",
              "      <td>37696</td>\n",
              "      <td>kris-ipeh</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37697</th>\n",
              "      <td>37697</td>\n",
              "      <td>qpautrat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37698</th>\n",
              "      <td>37698</td>\n",
              "      <td>Injabie3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37699</th>\n",
              "      <td>37699</td>\n",
              "      <td>caseycavanagh</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id            name  ml_target\n",
              "37695  37695  shawnwanderson          1\n",
              "37696  37696       kris-ipeh          0\n",
              "37697  37697        qpautrat          0\n",
              "37698  37698        Injabie3          1\n",
              "37699  37699   caseycavanagh          0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Last 5 rows of the target (labels) dataset:\")\n",
        "display(target_df.tail())  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8kLXN9cWJuZ"
      },
      "source": [
        "### Processing the dataset\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nR-ojoIjTGUJ"
      },
      "outputs": [],
      "source": [
        "feats = []\n",
        "feat_counts = []\n",
        "\n",
        "for i in range(len(data_raw)):\n",
        "    feat_list = data_raw[str(i)]\n",
        "    feat_counts.append(len(feat_list))\n",
        "    feats.extend(feat_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "PXboUx4ITOeB"
      },
      "outputs": [],
      "source": [
        "#We are counting the frequency of each feature and storing it in a dictionary called counter\n",
        "counter=collections.Counter(feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf5XC0i1W52m"
      },
      "source": [
        "<h4>Data Analysis</h4>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNIHQo3GHCqP",
        "outputId": "9fbc1b8e-75cb-4301-a3ab-b2486e226cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features for the first 5 nodes:\n",
            "\n",
            "[19, 17, 19, 15, 19]\n"
          ]
        }
      ],
      "source": [
        "print('Number of features for the first 5 nodes:\\n')\n",
        "print(feat_counts[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "GnyVSmf4XDLw",
        "outputId": "7be84f30-61ac-43fd-8455-440ca8244dc3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "top_features = [feature for feature, count in counter.most_common(10)]\n",
        "top_feature_counts = [count for feature, count in counter.most_common(10)]\n",
        "\n",
        "top_features_df = pd.DataFrame({'Features': top_features, 'Counts': top_feature_counts})\n",
        "\n",
        "\n",
        "top_features_df = top_features_df.sort_values(by='Counts', ascending=False)\n",
        "\n",
        "# Increase the size of the heatmap figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a heatmap with feature counts\n",
        "sns.heatmap(top_features_df[['Counts']].T, cmap='viridis', annot=True, fmt='d', annot_kws={\"size\": 12}, cbar=False)\n",
        "\n",
        "# Set the x-axis labels to feature names\n",
        "plt.xticks(ticks=[i + 0.5 for i in range(10)], labels=top_features, rotation=45, ha='right')\n",
        "\n",
        "plt.title('Top 10 Most Occurring Features Heatmap')\n",
        "save_fig('top_features_heatmap.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLHK-3X8Xbb8"
      },
      "source": [
        "<h4>Data Encoding</h4>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "TC0JGS64TTsV"
      },
      "outputs": [],
      "source": [
        "#Encoding the Data\n",
        "def encode_data(light=False,n=60):\n",
        "  #Trying to work with only 60 nodes due to limited computer resources\n",
        "    if light==True:\n",
        "        nodes_included=n\n",
        "    elif light==False:\n",
        "        nodes_included=len(data_raw)\n",
        "\n",
        "  #data_encoded dictionary will store all a list of all 4005 features for every (37,700) nodes filled with 1's and 0's depending on the presence of each feature\n",
        "    data_encoded={}\n",
        "    for i in range(nodes_included):#\n",
        "        one_hot_feat=np.array([0]*(max(feats)+1))\n",
        "        this_feat=data_raw[str(i)]\n",
        "        one_hot_feat[this_feat]=1\n",
        "        data_encoded[str(i)]=list(one_hot_feat)\n",
        "\n",
        "  #Sice the value (list) of each key (node) is 4005 elements long, mostly containing 1's and 0's, we are creating a sparse matrix\n",
        "    if light==True:\n",
        "        sparse_feat_matrix=np.zeros((1,max(feats)+1))\n",
        "        for j in range(nodes_included):\n",
        "            temp=np.array(data_encoded[str(j)]).reshape(1,-1)\n",
        "            sparse_feat_matrix=np.concatenate((sparse_feat_matrix,temp),axis=0)\n",
        "        sparse_feat_matrix=sparse_feat_matrix[1:,:]\n",
        "        return(data_encoded,sparse_feat_matrix)\n",
        "    elif light==False:\n",
        "        return(data_encoded, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0-pNUUYX9Ox"
      },
      "source": [
        "<h5>Sparse Matrix plotting the first 550 features in the first 100 nodes</h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "BUlKxgwNTWga",
        "outputId": "1d28b72a-75f6-4f9c-aaac-ff75aebeb953"
      },
      "outputs": [],
      "source": [
        "#since we cannot fit all 4005 features in the window, we are showing the first 550 feautures of the first 100 nodes by passing the value to the encoded function which will return a sparse matrix\n",
        "data_encoded_vis,sparse_feat_matrix_vis=encode_data(light=True,n=100)\n",
        "plt.figure(figsize=(50,50));\n",
        "plt.imshow(sparse_feat_matrix_vis[:,:550],cmap='Greys');\n",
        "plt.grid()\n",
        "save_fig('sparse_features.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCFvge5YYZjg"
      },
      "source": [
        "<h4> Constructing a Graph </h4>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cJ3qZbNkTZOj"
      },
      "outputs": [],
      "source": [
        "def construct_graph(data_encoded, light=False):\n",
        "    # Extract the node features from the input data and convert them to a tensor.\n",
        "    node_features_list = list(data_encoded.values())\n",
        "    node_features = torch.tensor(node_features_list)\n",
        "\n",
        "    # Extract node labels from the 'target_df' dataframe and convert them to a tensor.\n",
        "    node_labels = torch.tensor(target_df['ml_target'].values)\n",
        "\n",
        "    # Prepare the edge data from the 'edges' variable and create edge tensors.\n",
        "    edges_list = edges.values.tolist()\n",
        "    edge_index01 = torch.tensor(edges_list, dtype=torch.long).T\n",
        "    edge_index02 = torch.zeros(edge_index01.shape, dtype=torch.long)\n",
        "\n",
        "    # Create reverse edges by swapping source and target indices.\n",
        "    edge_index02[0, :] = edge_index01[1, :]\n",
        "    edge_index02[1, :] = edge_index01[0, :]\n",
        "\n",
        "    # Concatenate both the original and reverse edges to create a combined edge index.\n",
        "    edge_index0 = torch.cat((edge_index01, edge_index02), axis=1)\n",
        "\n",
        "    # Create a PyTorch Geometric 'Data' object representing the graph with node features, labels, and edges.\n",
        "    g = Data(x=node_features, y=node_labels, edge_index=edge_index0)\n",
        "\n",
        "    # Create a \"light\" version of the graph with reduced dimensions.\n",
        "    g_light = Data(x=node_features[:, 0:2], y=node_labels, edge_index=edge_index0[:, :55])\n",
        "\n",
        "    # If the 'light' parameter is True, return the light version; otherwise, return the full graph.\n",
        "    if light:\n",
        "        return g_light\n",
        "    else:\n",
        "        return g\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "2R8pxKyITcyr"
      },
      "outputs": [],
      "source": [
        "def draw_graph(data0):\n",
        "    # Check if the graph has more than 100 nodes.\n",
        "    if data0.num_nodes > 100:\n",
        "        # If it's a large graph, print a message and exit without plotting.\n",
        "        print(\"This is a big graph, cannot plot...\")\n",
        "        return\n",
        "\n",
        "    else:\n",
        "        # Convert the input PyTorch Geometric 'Data' object to a NetworkX graph.\n",
        "        data_nx = to_networkx(data0)\n",
        "\n",
        "        # Extract node colors from the 'data0' object based on node labels.\n",
        "        node_colors = data0.y[list(data_nx.nodes)]\n",
        "\n",
        "        # Compute the positions of nodes using the spring layout algorithm.\n",
        "        pos = nx.spring_layout(data_nx, scale=1)\n",
        "\n",
        "        # Create a Matplotlib figure for the graph visualization.\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Use NetworkX to draw the graph with various visualization settings.\n",
        "        nx.draw(data_nx, pos, cmap=plt.get_cmap('Set1'),\n",
        "                node_color=node_colors, node_size=600, connectionstyle=\"angle3\",\n",
        "                width=1, with_labels=True, edge_color='k', arrowstyle=\"-\")\n",
        "        save_fig('graph_sample.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "PSAbV5YrTgiF",
        "outputId": "4e59bd9a-d0fd-494c-f5fe-b3f9e6f54aac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_43640\\1330896778.py:7: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
            "  plt.tight_layout()\n"
          ]
        }
      ],
      "source": [
        "# Constructing the graph with 'g_light' representing the connection of edges.\n",
        "# The gray color represents Machine Learning (ML) while the Red represents Web Development.\n",
        "\n",
        "# The 'light' version is suitable for visualization with reduced dimensions.\n",
        "g_sample = construct_graph(data_encoded=data_encoded_vis, light=True)\n",
        "\n",
        "# Visualize the 'g_sample' graph.\n",
        "draw_graph(g_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Em1NSfw53iz"
      },
      "source": [
        "**GNN Model Construction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "dJaOU3GkTjj9"
      },
      "outputs": [],
      "source": [
        "data_encoded,_=encode_data(light=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1vu9CuKATrT5"
      },
      "outputs": [],
      "source": [
        "g=construct_graph(data_encoded=data_encoded,light=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFRCvCvxTwVB",
        "outputId": "38ab498b-efa3-4bc6-9512-d1ae2ce085ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[37700, 4005], edge_index=[2, 578006], y=[37700], train_mask=[37700], val_mask=[37700], test_mask=[37700])\n",
            "\n",
            "Training samples: 22620\n",
            "Validation samples: 11310\n",
            "Test samples: 3770\n"
          ]
        }
      ],
      "source": [
        "# Define the labels/targets (assuming they are in g)\n",
        "labels = g.y\n",
        "\n",
        "# Split the data into training, validation, and test sets based on the ration shown below\n",
        "train_ratio = 0.6\n",
        "val_ratio = 0.3\n",
        "test_ratio = 0.1\n",
        "\n",
        "train_idx, test_idx, train_labels, test_labels = train_test_split(\n",
        "    range(len(labels)), labels, test_size=test_ratio, random_state=42\n",
        ")\n",
        "\n",
        "train_idx, val_idx, train_labels, val_labels = train_test_split(\n",
        "    train_idx, train_labels, test_size=val_ratio / (1 - test_ratio), random_state=42\n",
        ")\n",
        "\n",
        "# Create mask tensors for training, validation, and test sets\n",
        "train_mask = torch.zeros(len(labels), dtype=torch.bool)\n",
        "val_mask = torch.zeros(len(labels), dtype=torch.bool)\n",
        "test_mask = torch.zeros(len(labels), dtype=torch.bool)\n",
        "\n",
        "train_mask[train_idx] = 1\n",
        "val_mask[val_idx] = 1\n",
        "test_mask[test_idx] = 1\n",
        "\n",
        "# Assign masks to the graph\n",
        "g.train_mask = train_mask\n",
        "g.val_mask = val_mask\n",
        "g.test_mask = test_mask\n",
        "\n",
        "print(g)\n",
        "print()\n",
        "print(\"Training samples:\", torch.sum(g.train_mask).item())\n",
        "print(\"Validation samples:\", torch.sum(g.val_mask).item())\n",
        "print(\"Test samples:\", torch.sum(g.test_mask).item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "cEHDqyCETyLV"
      },
      "outputs": [],
      "source": [
        "class SocialGNN(torch.nn.Module):\n",
        "    def __init__(self,num_of_feat,f):\n",
        "        super(SocialGNN, self).__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(num_of_feat, f)\n",
        "        self.conv2 = GCNConv(f, 2)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x.float()\n",
        "        edge_index =  data.edge_index\n",
        "\n",
        "        x = self.conv1(x=x, edge_index=edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "wrUb3X6MU8x2"
      },
      "outputs": [],
      "source": [
        "def masked_loss(predictions, labels, mask):\n",
        "    # Use only the nodes where mask == True\n",
        "    return criterion(predictions[mask], labels[mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "3YhGoSpbVAMP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def masked_accuracy(predictions, labels, mask):\n",
        "    # Class with highest score\n",
        "    preds = predictions.argmax(dim=1)\n",
        "    # Check correctness only on masked nodes\n",
        "    correct = (preds[mask] == labels[mask]).float()\n",
        "    # Mean accuracy on that subset\n",
        "    return correct.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "XOtXCZfVVJvp"
      },
      "outputs": [],
      "source": [
        "test_list = []\n",
        "def train_social(net, data, epochs=10, initial_lr=0.01):\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=initial_lr)\n",
        "    best_accuracy = 0.0\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)  # Learning rate scheduler\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for ep in range(epochs + 1):\n",
        "        optimizer.zero_grad()\n",
        "        out = net(data)\n",
        "        loss = masked_loss(predictions=out, labels=data.y, mask=data.train_mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_accuracy = masked_accuracy(predictions=out, labels=data.y, mask=data.train_mask)\n",
        "        train_accuracies.append(train_accuracy.item())\n",
        "\n",
        "        val_loss = masked_loss(predictions=out, labels=data.y, mask=data.val_mask)\n",
        "        val_losses.append(val_loss.item())\n",
        "        val_accuracy = masked_accuracy(predictions=out, labels=data.y, mask=data.val_mask)\n",
        "        val_accuracies.append(val_accuracy.item())\n",
        "\n",
        "        test_accuracy = masked_accuracy(predictions=out, labels=data.y, mask=data.test_mask)\n",
        "        test_accuracies.append(test_accuracy.item())\n",
        "        test_list.append(test_accuracy.item())\n",
        "\n",
        "        if np.round(val_accuracy.item(), 4) > np.round(best_accuracy, 4):\n",
        "            print(\"Epoch {}/{}, Train_Loss: {:.4f}, Train_Accuracy: {:.4f}, Val_Accuracy: {:.4f}, Test_Accuracy: {:.4f}\" \n",
        "                  .format(ep + 1, epochs, loss.item(), train_accuracy.item(), val_accuracy.item(), test_accuracy.item()))\n",
        "            best_accuracy = val_accuracy\n",
        "\n",
        "        # Learning rate schedule step\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Validation Loss\")\n",
        "    plt.plot(test_losses, label=\"Test Loss\")\n",
        "    plt.legend()\n",
        "    save_fig('gnn_losses.png')\n",
        "\n",
        "    plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "    plt.plot(test_accuracies, label=\"Test Accuracy\")\n",
        "    plt.legend()\n",
        "    save_fig('gnn_accuracies.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcBNpf1_53i0"
      },
      "source": [
        "**Running the model with Hyperparameter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SqAd3k-r53i1",
        "outputId": "a1d2741b-cb50-44a7-ca8a-266657db7f7f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Train_Loss: 0.6692, Train_Accuracy: 0.7431, Val_Accuracy: 0.7380, Test_Accuracy: 0.7435\n",
            "Epoch 3/50, Train_Loss: 0.5338, Train_Accuracy: 0.7758, Val_Accuracy: 0.7716, Test_Accuracy: 0.7743\n",
            "Epoch 3/50, Train_Loss: 0.5338, Train_Accuracy: 0.7758, Val_Accuracy: 0.7716, Test_Accuracy: 0.7743\n",
            "Epoch 5/50, Train_Loss: 0.4789, Train_Accuracy: 0.8454, Val_Accuracy: 0.8457, Test_Accuracy: 0.8318\n",
            "Epoch 5/50, Train_Loss: 0.4789, Train_Accuracy: 0.8454, Val_Accuracy: 0.8457, Test_Accuracy: 0.8318\n",
            "Epoch 6/50, Train_Loss: 0.3526, Train_Accuracy: 0.8615, Val_Accuracy: 0.8561, Test_Accuracy: 0.8536\n",
            "Epoch 6/50, Train_Loss: 0.3526, Train_Accuracy: 0.8615, Val_Accuracy: 0.8561, Test_Accuracy: 0.8536\n",
            "Epoch 13/50, Train_Loss: 0.3426, Train_Accuracy: 0.8652, Val_Accuracy: 0.8599, Test_Accuracy: 0.8586\n",
            "Epoch 13/50, Train_Loss: 0.3426, Train_Accuracy: 0.8652, Val_Accuracy: 0.8599, Test_Accuracy: 0.8586\n",
            "Epoch 14/50, Train_Loss: 0.3532, Train_Accuracy: 0.8695, Val_Accuracy: 0.8656, Test_Accuracy: 0.8552\n",
            "Epoch 14/50, Train_Loss: 0.3532, Train_Accuracy: 0.8695, Val_Accuracy: 0.8656, Test_Accuracy: 0.8552\n",
            "Epoch 18/50, Train_Loss: 0.3434, Train_Accuracy: 0.8692, Val_Accuracy: 0.8667, Test_Accuracy: 0.8541\n",
            "Epoch 18/50, Train_Loss: 0.3434, Train_Accuracy: 0.8692, Val_Accuracy: 0.8667, Test_Accuracy: 0.8541\n",
            "Epoch 27/50, Train_Loss: 0.3192, Train_Accuracy: 0.8717, Val_Accuracy: 0.8670, Test_Accuracy: 0.8602\n",
            "Epoch 27/50, Train_Loss: 0.3192, Train_Accuracy: 0.8717, Val_Accuracy: 0.8670, Test_Accuracy: 0.8602\n",
            "Epoch 28/50, Train_Loss: 0.3170, Train_Accuracy: 0.8730, Val_Accuracy: 0.8681, Test_Accuracy: 0.8576\n",
            "Epoch 28/50, Train_Loss: 0.3170, Train_Accuracy: 0.8730, Val_Accuracy: 0.8681, Test_Accuracy: 0.8576\n",
            "Epoch 30/50, Train_Loss: 0.3199, Train_Accuracy: 0.8733, Val_Accuracy: 0.8684, Test_Accuracy: 0.8549\n",
            "Epoch 30/50, Train_Loss: 0.3199, Train_Accuracy: 0.8733, Val_Accuracy: 0.8684, Test_Accuracy: 0.8549\n",
            "Epoch 32/50, Train_Loss: 0.3202, Train_Accuracy: 0.8733, Val_Accuracy: 0.8688, Test_Accuracy: 0.8533\n",
            "Epoch 32/50, Train_Loss: 0.3202, Train_Accuracy: 0.8733, Val_Accuracy: 0.8688, Test_Accuracy: 0.8533\n",
            "Epoch 36/50, Train_Loss: 0.3099, Train_Accuracy: 0.8750, Val_Accuracy: 0.8689, Test_Accuracy: 0.8618\n",
            "Epoch 36/50, Train_Loss: 0.3099, Train_Accuracy: 0.8750, Val_Accuracy: 0.8689, Test_Accuracy: 0.8618\n",
            "Epoch 43/50, Train_Loss: 0.3044, Train_Accuracy: 0.8763, Val_Accuracy: 0.8694, Test_Accuracy: 0.8623\n",
            "Epoch 43/50, Train_Loss: 0.3044, Train_Accuracy: 0.8763, Val_Accuracy: 0.8694, Test_Accuracy: 0.8623\n",
            "Epoch 45/50, Train_Loss: 0.3027, Train_Accuracy: 0.8776, Val_Accuracy: 0.8697, Test_Accuracy: 0.8631\n",
            "Epoch 45/50, Train_Loss: 0.3027, Train_Accuracy: 0.8776, Val_Accuracy: 0.8697, Test_Accuracy: 0.8631\n",
            "Epoch 46/50, Train_Loss: 0.3025, Train_Accuracy: 0.8782, Val_Accuracy: 0.8698, Test_Accuracy: 0.8621\n",
            "Epoch 46/50, Train_Loss: 0.3025, Train_Accuracy: 0.8782, Val_Accuracy: 0.8698, Test_Accuracy: 0.8621\n",
            "Epoch 47/50, Train_Loss: 0.3022, Train_Accuracy: 0.8789, Val_Accuracy: 0.8701, Test_Accuracy: 0.8610\n",
            "Epoch 47/50, Train_Loss: 0.3022, Train_Accuracy: 0.8789, Val_Accuracy: 0.8701, Test_Accuracy: 0.8610\n",
            "Epoch 51/50, Train_Loss: 0.2982, Train_Accuracy: 0.8794, Val_Accuracy: 0.8702, Test_Accuracy: 0.8639\n",
            "Epoch 51/50, Train_Loss: 0.2982, Train_Accuracy: 0.8794, Val_Accuracy: 0.8702, Test_Accuracy: 0.8639\n"
          ]
        }
      ],
      "source": [
        "num_of_feat=g.num_node_features\n",
        "net=SocialGNN(num_of_feat=num_of_feat,f=16)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "train_social(net,g,epochs=50,initial_lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvdP8UGn53i1"
      },
      "source": [
        "**Running the model with Different Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T6BERLxK53i1",
        "outputId": "bc969a7d-66e0-4d73-a8ad-da6b087c5dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Train_Loss: 0.6855, Train_Accuracy: 0.7309, Val_Accuracy: 0.7308, Test_Accuracy: 0.7385\n",
            "Epoch 2/100, Train_Loss: 0.6106, Train_Accuracy: 0.7434, Val_Accuracy: 0.7381, Test_Accuracy: 0.7438\n",
            "Epoch 2/100, Train_Loss: 0.6106, Train_Accuracy: 0.7434, Val_Accuracy: 0.7381, Test_Accuracy: 0.7438\n",
            "Epoch 6/100, Train_Loss: 0.5181, Train_Accuracy: 0.7436, Val_Accuracy: 0.7382, Test_Accuracy: 0.7440\n",
            "Epoch 6/100, Train_Loss: 0.5181, Train_Accuracy: 0.7436, Val_Accuracy: 0.7382, Test_Accuracy: 0.7440\n",
            "Epoch 7/100, Train_Loss: 0.5130, Train_Accuracy: 0.7439, Val_Accuracy: 0.7387, Test_Accuracy: 0.7451\n",
            "Epoch 7/100, Train_Loss: 0.5130, Train_Accuracy: 0.7439, Val_Accuracy: 0.7387, Test_Accuracy: 0.7451\n",
            "Epoch 8/100, Train_Loss: 0.5019, Train_Accuracy: 0.7446, Val_Accuracy: 0.7398, Test_Accuracy: 0.7456\n",
            "Epoch 8/100, Train_Loss: 0.5019, Train_Accuracy: 0.7446, Val_Accuracy: 0.7398, Test_Accuracy: 0.7456\n",
            "Epoch 9/100, Train_Loss: 0.4836, Train_Accuracy: 0.7472, Val_Accuracy: 0.7424, Test_Accuracy: 0.7485\n",
            "Epoch 9/100, Train_Loss: 0.4836, Train_Accuracy: 0.7472, Val_Accuracy: 0.7424, Test_Accuracy: 0.7485\n",
            "Epoch 10/100, Train_Loss: 0.4612, Train_Accuracy: 0.7557, Val_Accuracy: 0.7500, Test_Accuracy: 0.7560\n",
            "Epoch 10/100, Train_Loss: 0.4612, Train_Accuracy: 0.7557, Val_Accuracy: 0.7500, Test_Accuracy: 0.7560\n",
            "Epoch 11/100, Train_Loss: 0.4393, Train_Accuracy: 0.7751, Val_Accuracy: 0.7714, Test_Accuracy: 0.7745\n",
            "Epoch 11/100, Train_Loss: 0.4393, Train_Accuracy: 0.7751, Val_Accuracy: 0.7714, Test_Accuracy: 0.7745\n",
            "Epoch 12/100, Train_Loss: 0.4256, Train_Accuracy: 0.8035, Val_Accuracy: 0.7964, Test_Accuracy: 0.8045\n",
            "Epoch 12/100, Train_Loss: 0.4256, Train_Accuracy: 0.8035, Val_Accuracy: 0.7964, Test_Accuracy: 0.8045\n",
            "Epoch 13/100, Train_Loss: 0.4177, Train_Accuracy: 0.8303, Val_Accuracy: 0.8210, Test_Accuracy: 0.8260\n",
            "Epoch 13/100, Train_Loss: 0.4177, Train_Accuracy: 0.8303, Val_Accuracy: 0.8210, Test_Accuracy: 0.8260\n",
            "Epoch 14/100, Train_Loss: 0.4124, Train_Accuracy: 0.8450, Val_Accuracy: 0.8375, Test_Accuracy: 0.8419\n",
            "Epoch 14/100, Train_Loss: 0.4124, Train_Accuracy: 0.8450, Val_Accuracy: 0.8375, Test_Accuracy: 0.8419\n",
            "Epoch 15/100, Train_Loss: 0.4070, Train_Accuracy: 0.8540, Val_Accuracy: 0.8470, Test_Accuracy: 0.8480\n",
            "Epoch 15/100, Train_Loss: 0.4070, Train_Accuracy: 0.8540, Val_Accuracy: 0.8470, Test_Accuracy: 0.8480\n",
            "Epoch 16/100, Train_Loss: 0.3996, Train_Accuracy: 0.8581, Val_Accuracy: 0.8523, Test_Accuracy: 0.8528\n",
            "Epoch 16/100, Train_Loss: 0.3996, Train_Accuracy: 0.8581, Val_Accuracy: 0.8523, Test_Accuracy: 0.8528\n",
            "Epoch 17/100, Train_Loss: 0.3901, Train_Accuracy: 0.8595, Val_Accuracy: 0.8539, Test_Accuracy: 0.8538\n",
            "Epoch 17/100, Train_Loss: 0.3901, Train_Accuracy: 0.8595, Val_Accuracy: 0.8539, Test_Accuracy: 0.8538\n",
            "Epoch 24/100, Train_Loss: 0.3480, Train_Accuracy: 0.8605, Val_Accuracy: 0.8540, Test_Accuracy: 0.8536\n",
            "Epoch 24/100, Train_Loss: 0.3480, Train_Accuracy: 0.8605, Val_Accuracy: 0.8540, Test_Accuracy: 0.8536\n",
            "Epoch 25/100, Train_Loss: 0.3441, Train_Accuracy: 0.8617, Val_Accuracy: 0.8562, Test_Accuracy: 0.8546\n",
            "Epoch 25/100, Train_Loss: 0.3441, Train_Accuracy: 0.8617, Val_Accuracy: 0.8562, Test_Accuracy: 0.8546\n",
            "Epoch 26/100, Train_Loss: 0.3401, Train_Accuracy: 0.8634, Val_Accuracy: 0.8575, Test_Accuracy: 0.8546\n",
            "Epoch 26/100, Train_Loss: 0.3401, Train_Accuracy: 0.8634, Val_Accuracy: 0.8575, Test_Accuracy: 0.8546\n",
            "Epoch 27/100, Train_Loss: 0.3364, Train_Accuracy: 0.8649, Val_Accuracy: 0.8587, Test_Accuracy: 0.8552\n",
            "Epoch 27/100, Train_Loss: 0.3364, Train_Accuracy: 0.8649, Val_Accuracy: 0.8587, Test_Accuracy: 0.8552\n",
            "Epoch 28/100, Train_Loss: 0.3336, Train_Accuracy: 0.8660, Val_Accuracy: 0.8614, Test_Accuracy: 0.8594\n",
            "Epoch 28/100, Train_Loss: 0.3336, Train_Accuracy: 0.8660, Val_Accuracy: 0.8614, Test_Accuracy: 0.8594\n",
            "Epoch 29/100, Train_Loss: 0.3319, Train_Accuracy: 0.8681, Val_Accuracy: 0.8630, Test_Accuracy: 0.8613\n",
            "Epoch 29/100, Train_Loss: 0.3319, Train_Accuracy: 0.8681, Val_Accuracy: 0.8630, Test_Accuracy: 0.8613\n",
            "Epoch 30/100, Train_Loss: 0.3311, Train_Accuracy: 0.8691, Val_Accuracy: 0.8645, Test_Accuracy: 0.8594\n",
            "Epoch 30/100, Train_Loss: 0.3311, Train_Accuracy: 0.8691, Val_Accuracy: 0.8645, Test_Accuracy: 0.8594\n",
            "Epoch 31/100, Train_Loss: 0.3305, Train_Accuracy: 0.8696, Val_Accuracy: 0.8656, Test_Accuracy: 0.8592\n",
            "Epoch 31/100, Train_Loss: 0.3305, Train_Accuracy: 0.8696, Val_Accuracy: 0.8656, Test_Accuracy: 0.8592\n",
            "Epoch 32/100, Train_Loss: 0.3296, Train_Accuracy: 0.8702, Val_Accuracy: 0.8660, Test_Accuracy: 0.8581\n",
            "Epoch 32/100, Train_Loss: 0.3296, Train_Accuracy: 0.8702, Val_Accuracy: 0.8660, Test_Accuracy: 0.8581\n",
            "Epoch 33/100, Train_Loss: 0.3282, Train_Accuracy: 0.8707, Val_Accuracy: 0.8666, Test_Accuracy: 0.8594\n",
            "Epoch 33/100, Train_Loss: 0.3282, Train_Accuracy: 0.8707, Val_Accuracy: 0.8666, Test_Accuracy: 0.8594\n",
            "Epoch 42/100, Train_Loss: 0.3193, Train_Accuracy: 0.8728, Val_Accuracy: 0.8672, Test_Accuracy: 0.8618\n",
            "Epoch 42/100, Train_Loss: 0.3193, Train_Accuracy: 0.8728, Val_Accuracy: 0.8672, Test_Accuracy: 0.8618\n",
            "Epoch 43/100, Train_Loss: 0.3183, Train_Accuracy: 0.8729, Val_Accuracy: 0.8680, Test_Accuracy: 0.8610\n",
            "Epoch 43/100, Train_Loss: 0.3183, Train_Accuracy: 0.8729, Val_Accuracy: 0.8680, Test_Accuracy: 0.8610\n",
            "Epoch 44/100, Train_Loss: 0.3175, Train_Accuracy: 0.8731, Val_Accuracy: 0.8685, Test_Accuracy: 0.8610\n",
            "Epoch 44/100, Train_Loss: 0.3175, Train_Accuracy: 0.8731, Val_Accuracy: 0.8685, Test_Accuracy: 0.8610\n",
            "Epoch 45/100, Train_Loss: 0.3169, Train_Accuracy: 0.8740, Val_Accuracy: 0.8687, Test_Accuracy: 0.8613\n",
            "Epoch 45/100, Train_Loss: 0.3169, Train_Accuracy: 0.8740, Val_Accuracy: 0.8687, Test_Accuracy: 0.8613\n",
            "Epoch 46/100, Train_Loss: 0.3163, Train_Accuracy: 0.8744, Val_Accuracy: 0.8691, Test_Accuracy: 0.8621\n",
            "Epoch 46/100, Train_Loss: 0.3163, Train_Accuracy: 0.8744, Val_Accuracy: 0.8691, Test_Accuracy: 0.8621\n"
          ]
        }
      ],
      "source": [
        "num_of_feat=g.num_node_features\n",
        "net=SocialGNN(num_of_feat=num_of_feat,f=16)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "train_social(net,g,epochs=100,initial_lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw2k3UhZS9ks"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97yIzR5D53i1"
      },
      "source": [
        "**Making Dataframe out of encoded data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "MqTADPpyIUpb"
      },
      "outputs": [],
      "source": [
        "X_encoded = pd.DataFrame(data_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cEhOwEyYIesP"
      },
      "outputs": [],
      "source": [
        "y = target_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "BXH7pIjeK06y"
      },
      "outputs": [],
      "source": [
        "transposed_df = X_encoded.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "OpGYmzZfLgIt",
        "outputId": "ba4bfbd6-568b-443c-d7c6-a48bae70b805"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>3995</th>\n",
              "      <th>3996</th>\n",
              "      <th>3997</th>\n",
              "      <th>3998</th>\n",
              "      <th>3999</th>\n",
              "      <th>4000</th>\n",
              "      <th>4001</th>\n",
              "      <th>4002</th>\n",
              "      <th>4003</th>\n",
              "      <th>4004</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 4005 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     ...  3995  \\\n",
              "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "\n",
              "   3996  3997  3998  3999  4000  4001  4002  4003  4004  \n",
              "0     0     0     0     0     0     0     0     0     0  \n",
              "1     0     0     0     0     0     0     0     0     0  \n",
              "2     0     0     0     0     0     0     0     0     0  \n",
              "3     0     0     0     0     0     0     0     1     0  \n",
              "4     0     0     0     0     0     0     0     0     0  \n",
              "\n",
              "[5 rows x 4005 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transposed_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PudsENFl53i2"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx9cGkuKCtNr",
        "outputId": "da1784e6-fb7a-4870-c78d-0cd79b000cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy in iteration 1 is 44.22%\n",
            "Accuracy in iteration 2 is 43.56%\n",
            "Accuracy in iteration 2 is 43.56%\n",
            "Accuracy in iteration 3 is 45.35%\n",
            "Accuracy in iteration 3 is 45.35%\n",
            "Accuracy in iteration 4 is 44.65%\n",
            "Average accuracy: 44.45%\n",
            "\n",
            "Confusion Matrix for Test Data:\n",
            "Accuracy in iteration 4 is 44.65%\n",
            "Average accuracy: 44.45%\n",
            "\n",
            "Confusion Matrix for Test Data:\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Split the data using 4-Fold Cross Validation\n",
        "kf = KFold(n_splits=4)\n",
        "accuracy_scores = []\n",
        "confusion_matrices = []  # To store confusion matrices for each fold\n",
        "\n",
        "# Counter variable to keep track of each fold\n",
        "k = 1\n",
        "\n",
        "for train_index, test_index in kf.split(y):\n",
        "    # Split the data into training and testing sets based on the current fold\n",
        "    X_train, X_test = transposed_df.iloc[train_index], transposed_df.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Define the classifier\n",
        "    naive_bayes_classifier = GaussianNB()\n",
        "    naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = naive_bayes_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    confusion_test = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Print accuracy for the current iteration\n",
        "    print(f\"Accuracy in iteration {k} is {accuracy * 100:.2f}%\")\n",
        "    k += 1\n",
        "\n",
        "    # Append the accuracy to the list\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Append the confusion matrix to the list\n",
        "    confusion_matrices.append(confusion_test)\n",
        "\n",
        "# Calculate the average accuracy\n",
        "avg_acc = sum(accuracy_scores) / len(accuracy_scores)\n",
        "\n",
        "# Calculate the average confusion matrix\n",
        "avg_confusion_matrix = sum(confusion_matrices) / len(confusion_matrices)\n",
        "\n",
        "print(f'Average accuracy: {avg_acc * 100:.2f}%')\n",
        "\n",
        "# Calculate the average confusion matrix as integers\n",
        "avg_confusion_matrix_int = avg_confusion_matrix.astype(int)\n",
        "print()\n",
        "# Print the average confusion matrix\n",
        "print(\"Confusion Matrix for Test Data:\")\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(avg_confusion_matrix_int, annot=True, fmt='d', cmap='viridis',\n",
        "            xticklabels=range(2), yticklabels=range(2))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix -Naive Bayes')\n",
        "save_fig('confusion_naivebayes.png')\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "FkFQm2vn53i6",
        "outputId": "038bc786-b0d4-4ab3-c073-dd2088bdb6cb"
      },
      "outputs": [],
      "source": [
        "# Filter data based on conditions for the second dataset\n",
        "y_test_0_lr = len(y_test[y_test == 0])\n",
        "y_test_1_lr = len(y_test[y_test == 1])\n",
        "y_pred_0_lr = len(y_pred[y_pred == 0])\n",
        "y_pred_1_lr = len(y_pred[y_pred == 1])\n",
        "\n",
        "conditions = [\"Web Actual\", \"ML Actual\", \"Web Predicted\", \"ML Actual\"]\n",
        "colors = ['b', 'b', 'g', 'g']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-k9I1Ho53i6"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "oKO-Kxp7NAyU",
        "outputId": "7f2465d8-c61f-4fac-91e6-5c508caa332a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy in iteration 1 is 83.07%\n",
            "\n",
            "Accuracy in iteration 2 is 83.62%\n",
            "\n",
            "Accuracy in iteration 2 is 83.62%\n",
            "\n",
            "Accuracy in iteration 3 is 83.28%\n",
            "\n",
            "Accuracy in iteration 3 is 83.28%\n",
            "\n",
            "Accuracy in iteration 4 is 83.72%\n",
            "\n",
            "Average accuracy: 83.42%\n",
            "Confusion Matrix for Test Data:\n",
            "Accuracy in iteration 4 is 83.72%\n",
            "\n",
            "Average accuracy: 83.42%\n",
            "Confusion Matrix for Test Data:\n"
          ]
        }
      ],
      "source": [
        "\n",
        "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "accuracy_scores_logisticRegression = []\n",
        "confusion_matrices_lr = []  # Initialize the confusion matrices list\n",
        "\n",
        "k = 1\n",
        "\n",
        "for train_index, test_index in kf.split(transposed_df):  # Changed 'y' to 'transposed_df'\n",
        "    X_train, X_test = transposed_df.iloc[train_index], transposed_df.iloc[test_index]\n",
        "    y_train, y_test_lr = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    logisticRegression = LogisticRegression(max_iter=1000, solver='liblinear', C=0.1, class_weight='balanced', penalty='l1')\n",
        "    logisticRegression.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_lr = logisticRegression.predict(X_test)\n",
        "    accuracy_logisticRegression = accuracy_score(y_test_lr, y_pred_lr)\n",
        "    confusion_test_lr = confusion_matrix(y_test_lr, y_pred_lr)\n",
        "\n",
        "    # Append the confusion matrix to the list\n",
        "    confusion_matrices_lr.append(confusion_test_lr)\n",
        "\n",
        "    print(f\"Accuracy in iteration {k} is {accuracy_logisticRegression * 100:.2f}%\")\n",
        "    print()\n",
        "\n",
        "    accuracy_scores_logisticRegression.append(accuracy_logisticRegression)\n",
        "\n",
        "    k += 1\n",
        "\n",
        "avg_acc_logisticRegression = np.mean(accuracy_scores_logisticRegression)  # Use np.mean to calculate the average\n",
        "\n",
        "print(f'Average accuracy: {avg_acc_logisticRegression * 100:.2f}%')\n",
        "\n",
        "# Calculate the average confusion matrix\n",
        "avg_confusion_matrix_lr = np.mean(confusion_matrices_lr, axis=0)  # Use np.mean to calculate the average\n",
        "\n",
        "# Calculate the average confusion matrix as integers\n",
        "avg_confusion_matrix_int_lr = avg_confusion_matrix_lr.astype(int)\n",
        "\n",
        "# Print the average confusion matrix\n",
        "print(\"Confusion Matrix for Test Data:\")\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(avg_confusion_matrix_int_lr, annot=True, fmt='d', cmap='viridis',\n",
        "            xticklabels=range(2), yticklabels=range(2))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix -Logistic Regression')\n",
        "save_fig('confusion_logistic.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ruV3uG0O53i7",
        "outputId": "b89cc2da-4fe5-4400-8ab3-8d49da211c4f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filter data based on conditions for the second dataset\n",
        "y_test_0_lr = len(y_test_lr[y_test_lr == 0])\n",
        "y_test_1_lr = len(y_test_lr[y_test_lr == 1])\n",
        "y_pred_0_lr = len(y_pred_lr[y_pred_lr == 0])\n",
        "y_pred_1_lr = len(y_pred_lr[y_pred_lr == 1])\n",
        "\n",
        "conditions = [\"Web Actual\", \"ML Actual\", \"Web Predicted\", \"ML Actual\"]\n",
        "colors = ['b', 'b', 'g', 'g']\n",
        "\n",
        "bar_width = 0.5\n",
        "x = [i for i in range(len(conditions))]\n",
        "counts = [y_test_0_lr, y_test_1_lr, y_pred_0_lr, y_pred_1_lr]\n",
        "\n",
        "plt.figure(figsize=(4, 6))  # Adjust the figure size as needed\n",
        "\n",
        "# Create the bar chart with the same width and appearance\n",
        "plt.bar(x, counts, color=colors, width=bar_width, alpha=0.4)\n",
        "plt.xticks(x, conditions, rotation=45)\n",
        "plt.xlabel('Condition')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Actual Labels VS Predicted Labels -Logistic Regression')\n",
        "plt.tight_layout()\n",
        "save_fig('actual_vs_predicted_lr.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW5QnJ1l53i7"
      },
      "source": [
        "**Comparing Accuracies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "1Osjwi3C53i7",
        "outputId": "fcb0936e-cb1f-4952-f4b3-61bcb2fdb908",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Average CV accuracies\n",
        "avg_acc_nb = np.mean(accuracy_scores)\n",
        "avg_acc_lr = np.mean(accuracy_scores_logisticRegression)\n",
        "\n",
        "# GNN: take the last recorded test accuracy from the last training run\n",
        "gnn_test_acc = test_list[-1]\n",
        "\n",
        "models = [\"Naive Bayes\", \"Logistic Regression\", \"SocialGNN\"]\n",
        "avg_accuracies = [avg_acc_nb, avg_acc_lr, gnn_test_acc]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(models, avg_accuracies)\n",
        "plt.ylim(0.0, 1.0)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model comparison (average accuracy)\")\n",
        "save_fig('model_comparison.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HykMiLDO5775"
      },
      "source": [
        "Reference:\n",
        "\n",
        "- Awadelrahman. (2021, July 13). Tutorial Graph Neural networks on social networks. Kaggle. https://www.kaggle.com/code/awadelrahman/tutorial-graph-neural-networks-on-social-networks\n",
        "- Awan, A. A. (2022, July 21). A Comprehensive Introduction to Graph Neural Networks (GNNs). https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
        "- DARPAtv. (2017, February 15). A DARPA perspective on Artificial intelligence [Video]. YouTube. https://www.youtube.com/watch?v=-O01G3tSYpU\n",
        "- Khare, P. (2023, August 8). Unravelling Node2Vec: A Guide to Node Embeddings with Python Implementation. Medium. https://medium.com/illumination/unravelling-node2vec-a-guide-to-node-embeddings-with-python-implementation-c131603153bd\n",
        "- PyG Documentation â€” pytorch_geometric  documentation. (n.d.). https://pytorch-geometric.readthedocs.io/en/latest/index.html#\n",
        "- SNAP: Network datasets: Social circles. (n.d.). https://snap.stanford.edu/data/github-social.html\n",
        "-TensorFlow. (2021, June 17). Intro to graph neural networks (ML Tech Talks) [Video]. YouTube. https://www.youtube.com/watch?v=8owQBFAHw7E\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nHNhO6bEhKa"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
